{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8dd0be367c230a98263cb401f360bd5e3dc8a433d870bfd6659eb5c001b833a8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Handling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import tensorflow.keras.datasets.mnist as mnist\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "source": [
    "## Gather images\n",
    "\n",
    "We will be using a small non-medical images initially as a proof of concept. The obvious choice is the MNIST dataset, so we shall import the which is built into Keras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = mnist.load_data()"
   ]
  },
  {
   "source": [
    "The data is split into two arrays, the train and test sets. Each of those are then split into arrays for image data and class labels. We shall split these up."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = mnist_data[0]\n",
    "data_test = mnist_data[1]\n",
    "\n",
    "X_train, y_train = data_train[0], data_train[1]\n",
    "X_test, y_test = data_test[0], data_test[1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)"
   ]
  },
  {
   "source": [
    "Now we can organise in the data directory for the data generator.\n",
    "\n",
    "First we will need to make the classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def getdirs(classes):\n",
    "    cwd = os.getcwd()    \n",
    "    dir_sets = []\n",
    "    for s in [\"train\", \"val\", \"test\"]:\n",
    "        dirs = []\n",
    "        for c in classes:\n",
    "            dir = \"data/{0}/{1}/\".format(s, c)\n",
    "            dirs.append(os.path.join(cwd, dir))\n",
    "        dir_sets.append(dirs)\n",
    "    return dir_sets\n",
    "\n",
    "def mkdirs(classes):\n",
    "    dir_sets = getdirs(classes)\n",
    "    for dirs in dir_sets:\n",
    "        for dir in dirs:\n",
    "            if not os.path.isdir(dir):    \n",
    "                os.makedirs(dir)\n",
    "            else:\n",
    "                for filepath in os.listdir(dir):\n",
    "                    os.remove(os.path.join(dir, filepath))\n",
    "\n",
    "classes = range(10)\n",
    "mkdirs(classes)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "Now we can organise the images into the directories."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_imgs(classes, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    dir_sets = getdirs(classes)\n",
    "    sets = [(X_train, y_train), (X_val, y_val), (X_test, y_test)]\n",
    "    for (dirs, (X, y)) in zip(dir_sets, sets):\n",
    "        counter = [0] * len(classes)\n",
    "        for (img, label) in zip(X, y):\n",
    "            filename = \"{0}class_{1}_img_{2}.jpg\".format(dirs[label], label, counter[label])\n",
    "            cv.imwrite(filename, img)\n",
    "            counter[label] += 1\n",
    "\n",
    "write_imgs(classes, X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  }
 ]
}